{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference\n",
    "# https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA DESCRIPTION\n",
    "\n",
    "#     1. CRIM      per capita crime rate by town\n",
    "#     2. ZN        proportion of residential land zoned for lots over \n",
    "#                  25,000 sq.ft.\n",
    "#     3. INDUS     proportion of non-retail business acres per town\n",
    "#     4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "#                  river; 0 otherwise)\n",
    "#     5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "#     6. RM        average number of rooms per dwelling\n",
    "#     7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "#     8. DIS       weighted distances to five Boston employment centres\n",
    "#     9. RAD       index of accessibility to radial highways\n",
    "#     10. TAX      full-value property-tax rate per $10,000\n",
    "#     11. PTRATIO  pupil-teacher ratio by town\n",
    "#     12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
    "#                  by town\n",
    "#     13. LSTAT    % lower status of the population\n",
    "#     14. MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD DATA\n",
    "train = pd.read_csv('housing_train.txt', sep = \"\\s+\",header=None)\n",
    "#data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "\n",
    "#split into features and labels\n",
    "train_x = train.iloc[:,0:13]\n",
    "train_y = train.iloc[:,13]\n",
    "\n",
    "test = pd.read_csv('housing_test.txt', sep = \"\\s+\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TERMINAL NODES\n",
    "\n",
    "# Create a terminal node value - Gets mean value of group\n",
    "def to_terminal(group):\n",
    "    return group.iloc[:,13].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD TREE\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 0)\n",
    "    return root\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "#     if not left or not right:\n",
    "#         node['left'] = node['right'] = to_terminal(left + right)\n",
    "#         return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "        \n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['col']+1), node['val'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLITS\n",
    "\n",
    "# Split a dataset based on an column and an attribute value\n",
    "# RETURNS 2 dataframes\n",
    "def test_split(col, value, dataset):\n",
    "    left = dataset.loc[dataset[col] < value]\n",
    "    right = dataset.loc[dataset[col] >= value]\n",
    "    return left, right\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    b_col, b_val, b_vari, b_groups = np.inf, np.inf, np.inf, None\n",
    "    b_vari = np.var(dataset.iloc[:,13])\n",
    "    #iterate rows\n",
    "    for col in dataset.iloc[:,:-1]:\n",
    "        colmax = round(dataset[col].max(),3)\n",
    "        colmin = round(dataset[col].min(),3)\n",
    "        test_values = np.linspace(colmin,colmax,20)\n",
    "        \n",
    "        for i in test_values:   \n",
    "            groups = test_split(col, i, dataset)\n",
    "            \n",
    "            vari = 0\n",
    "            for g in groups:\n",
    "                #print(\"len: \" + str(len(g)))\n",
    "                vari += np.var(g.iloc[:,13]) * (len(g)/len(dataset))\n",
    "            #print('X%d < %.3f Variance=%.3f' % ((col+1), dataset.iloc[index,col], vari))\n",
    "               \n",
    "            if vari < b_vari:\n",
    "                b_vari = vari\n",
    "                b_col = col\n",
    "                b_groups = groups\n",
    "                b_val = i\n",
    "                \n",
    "    return {'col':b_col, 'val':b_val, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['col']] < node['val']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification and Regression Tree Algorithm returns MSE\n",
    "def decision_tree(train, test, max_depth, min_size):\n",
    "    tree = build_tree(train, max_depth, min_size)\n",
    "    predictions = list()\n",
    "    for i in range(len(test[0])):\n",
    "        prediction = predict(tree, test.iloc[i,:])\n",
    "        predictions.append(prediction)\n",
    "    mse = 0\n",
    "    for i in range(len(predictions)):\n",
    "        mse += ((predictions[i] - test.iloc[i,13]) ** 2) / 433\n",
    "    return(mse, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Depth: 3\n",
      "Train Error: 14.380032646726978\n",
      "Test Error: 23.125225336875257\n",
      "Tree Depth: 6\n",
      "Train Error: 6.712191923096406\n",
      "Test Error: 17.33541176521059\n",
      "Tree Depth: 9\n",
      "Train Error: 4.304423529956529\n",
      "Test Error: 19.618981170376376\n",
      "Tree Depth: 12\n",
      "Train Error: 3.4560016811329484\n",
      "Test Error: 20.312433724825823\n",
      "Tree Depth: 15\n",
      "Train Error: 3.313946937204444\n",
      "Test Error: 19.832812160821533\n",
      "Tree Depth: 18\n",
      "Train Error: 3.2986698009457838\n",
      "Test Error: 20.086621282443158\n"
     ]
    }
   ],
   "source": [
    "tree_depths = [3,6,9,12,15,18]\n",
    "for j in tree_depths:\n",
    "    print(\"Tree Depth: \" + str(j))\n",
    "    train_error, train_tree = decision_tree(train, train, j, 8)\n",
    "    print('Train Error: ' + str(train_error))\n",
    "    #TEST ERROR\n",
    "    predictions = list()\n",
    "    for i in range(len(test[0])):\n",
    "        prediction = predict(train_tree, test.iloc[i,:])\n",
    "        predictions.append(prediction)\n",
    "        mse = 0\n",
    "        for i in range(len(predictions)):\n",
    "            mse += ((predictions[i] - test.iloc[i,13]) ** 2) / len(predictions)\n",
    "    print('Test Error: ' + str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Depth: 3\n",
      "Train Error: 14.380032646726978\n",
      "Test Error: 23.125225336875257\n",
      "Tree Depth: 4\n",
      "Train Error: 9.667072556113034\n",
      "Test Error: 19.577508279780787\n",
      "Tree Depth: 5\n",
      "Train Error: 8.03007393627163\n",
      "Test Error: 17.887270403722635\n",
      "Tree Depth: 6\n",
      "Train Error: 6.712191923096406\n",
      "Test Error: 17.33541176521059\n",
      "Tree Depth: 7\n",
      "Train Error: 5.542935093768232\n",
      "Test Error: 18.26105675180934\n",
      "Tree Depth: 8\n",
      "Train Error: 4.913438257115118\n",
      "Test Error: 18.396344532282598\n",
      "Tree Depth: 9\n",
      "Train Error: 4.304423529956529\n",
      "Test Error: 19.618981170376376\n"
     ]
    }
   ],
   "source": [
    "tree_depths = [3,4,5,6,7,8,9]\n",
    "for j in tree_depths:\n",
    "    print(\"Tree Depth: \" + str(j))\n",
    "    train_error, train_tree = decision_tree(train, train, j, 8)\n",
    "    print('Train Error: ' + str(train_error))\n",
    "    #TEST ERROR\n",
    "    predictions = list()\n",
    "    for i in range(len(test[0])):\n",
    "        prediction = predict(train_tree, test.iloc[i,:])\n",
    "        predictions.append(prediction)\n",
    "        mse = 0\n",
    "        for i in range(len(predictions)):\n",
    "            mse += ((predictions[i] - test.iloc[i,13]) ** 2) / len(predictions)\n",
    "    print('Test Error: ' + str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error, train_tree = decision_tree(train, train, 15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST ERROR\n",
    "predictions = list()\n",
    "for i in range(len(test[0])):\n",
    "    prediction = predict(train_tree, test.iloc[i,:])\n",
    "    predictions.append(prediction)\n",
    "    mse = 0\n",
    "    for i in range(len(predictions)):\n",
    "        mse += ((predictions[i] - test.iloc[i,13]) ** 2) / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
