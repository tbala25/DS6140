{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference\n",
    "# https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/\n",
    "# https://machinelearningmastery.com/implement-resampling-methods-scratch-python/\n",
    "\n",
    "#http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.DOCUMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD DATA\n",
    "data = pd.read_csv('spambase_data.txt', sep = \",\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##K-FOLDS\n",
    "\n",
    "k = 5\n",
    "fold_size = math.ceil(len(data) / k)\n",
    "dataset_split = list()\n",
    "ind_count = 0\n",
    "for i in range(k):\n",
    "    #print(i)\n",
    "    dataset_split.append(data.iloc[ind_count:ind_count+fold_size,:])\n",
    "    ind_count = ind_count + fold_size + 1\n",
    "    \n",
    "def create_train_test(train_ind, test_ind):\n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    for i in train_ind:\n",
    "        train = train.append(dataset_split[i])\n",
    "    #for i in test_ind:\n",
    "    test = test.append(dataset_split[i])\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TERMINAL NODES\n",
    "\n",
    "# Create a terminal node value - Gets mean value of group\n",
    "def to_terminal(group):\n",
    "    outcomes = group.iloc[:,57]\n",
    "    if len(outcomes) > 0:\n",
    "        return (Counter(outcomes).most_common(1)[0][0])\n",
    "    else:\n",
    "        return(0)\n",
    "    #return max(set(outcomes), key=outcomes.count)\n",
    "    #return (Counter(outcomes).most_common(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##ENTROPY\n",
    "def get_entropy(groups):\n",
    "    entropy_node = 0  #Initialize Entropy\n",
    "      \n",
    "    entropy = 0\n",
    "    #if groups is actually just 1 df\n",
    "    if len(groups) > 2:\n",
    "        values = groups[57].unique()\n",
    "        for value in values:\n",
    "            fraction = groups.iloc[:,57].value_counts()[value]/len(groups.iloc[:,57])  \n",
    "            entropy_node += -fraction*np.log2(fraction)\n",
    "        entropy = entropy_node\n",
    "    #if groups is (df,df)\n",
    "    else:\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        for g in groups:\n",
    "            values = g[57].unique()\n",
    "            #print(g)\n",
    "            for value in values:\n",
    "                fraction = g.iloc[:,57].value_counts()[value]/len(g.iloc[:,57])  \n",
    "                entropy_node += -fraction*np.log2(fraction)\n",
    "            entropy += entropy_node * (len(g)/n_instances)\n",
    "    return(entropy)\n",
    "        \n",
    "def information_gain(ent_orig, ent_split):\n",
    "    return(ent_orig - ent_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD TREE\n",
    "\n",
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    #print(root)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "# Create child splits for a node or make terminal\n",
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "#     if not left or not right:\n",
    "#         node['left'] = node['right'] = to_terminal(left + right)\n",
    "#         return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)\n",
    "        \n",
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['col']+1), node['val'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPLITS\n",
    "\n",
    "# Split a dataset based on an column and an attribute value\n",
    "# RETURNS 2 dataframes\n",
    "def test_split(col, value, dataset):\n",
    "    left = dataset.loc[dataset[col] < value]\n",
    "    right = dataset.loc[dataset[col] >= value]\n",
    "    return left, right\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_split(dataset):\n",
    "    b_col, b_val, b_ig, b_groups = np.inf, np.inf, None, None\n",
    "    \n",
    "    #iterate rows\n",
    "    for col in dataset.iloc[:,:-1]:\n",
    "        colmax = dataset[col].max()\n",
    "        colmin = dataset[col].min()\n",
    "        test_values = np.linspace(colmin,colmax,100)\n",
    "        \n",
    "        for i in test_values:\n",
    "            groups = test_split(col, i, dataset)\n",
    "            #print(groups)\n",
    "            ig = information_gain(get_entropy(dataset), get_entropy(groups))\n",
    "            #print(ig)\n",
    "            if b_ig is None:\n",
    "                b_ig = ig\n",
    "                b_col = col\n",
    "                b_groups = groups\n",
    "                b_val = i\n",
    "            elif ig > b_ig:\n",
    "                b_ig = ig\n",
    "                b_col = col\n",
    "                b_groups = groups\n",
    "                b_val = i\n",
    "                \n",
    "    return {'col':b_col, 'val':b_val, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    if row[node['col']] < node['val']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "        \n",
    "# Classification and Regression Tree Algorithm returns MSE\n",
    "def decision_tree(tree, test):\n",
    "    #tree = build_tree(train, max_depth, min_size)\n",
    "    predictions = list()\n",
    "    for i in range(len(test[0])):\n",
    "        prediction = predict(tree, test.iloc[i,:])\n",
    "        predictions.append(prediction)\n",
    "    mse = 0\n",
    "    for i in range(len(predictions)):\n",
    "        mse += ((predictions[i] - test.iloc[i,57]) ** 2) / len(predictions)\n",
    "    return(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dec_tree(k, train_ind, test_ind):\n",
    "    print(\"Epoch \" + str(k+1))\n",
    "    train,test = create_train_test(train_ind, test_ind)\n",
    "    tree = build_tree(train, 5, 10)\n",
    "\n",
    "    train_error = decision_tree(tree,train)\n",
    "    print('Train MSE: ' + str(train_error))\n",
    "    test_error = decision_tree(tree,test)\n",
    "    print('Test MSE: ' + str(test_error))\n",
    "    return(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train MSE: 0.0696409140369967\n",
      "Test MSE: 0.03285870755750272\n",
      "Epoch 2\n",
      "Train MSE: 0.07100108813928176\n",
      "Test MSE: 0.04819277108433732\n",
      "Epoch 3\n",
      "Train MSE: 0.10418933623503725\n",
      "Test MSE: 0.06243154435925516\n",
      "Epoch 4\n",
      "Train MSE: 0.10799782372143542\n",
      "Test MSE: 0.12924424972617776\n",
      "Epoch 5\n",
      "Train MSE: 0.15960912052117268\n",
      "Test MSE: 0.3463626492942455\n",
      "Average Test MSE: 0.1238179844043037\n"
     ]
    }
   ],
   "source": [
    "#LOOCV\n",
    "total_mse = 0\n",
    "\n",
    "for i in range(k):\n",
    "    test_ind = i\n",
    "    train_ind = [x for x in range(k) if x!=i]\n",
    "    #train,test = create_train_test(train_ind, test_ind)\n",
    "    total_mse += init_dec_tree(i, train_ind, test_ind)\n",
    "print(\"Average Test MSE: \" + str(total_mse/k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train,test = create_train_test(train_ind, test_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_error, train_tree = decision_tree(train, train, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c0d4e6486892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutcomes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "outcomes = []\n",
    "Counter(outcomes).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
