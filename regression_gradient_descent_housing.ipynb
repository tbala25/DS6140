{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference\n",
    "# https://mubaris.com/posts/linear-regression/\n",
    "# https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f\n",
    "# β̂ ridgeλ=(XTX+λIp)−1XTy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA DESCRIPTION\n",
    "\n",
    "#     1. CRIM      per capita crime rate by town\n",
    "#     2. ZN        proportion of residential land zoned for lots over \n",
    "#                  25,000 sq.ft.\n",
    "#     3. INDUS     proportion of non-retail business acres per town\n",
    "#     4. CHAS      Charles River dummy variable (= 1 if tract bounds \n",
    "#                  river; 0 otherwise)\n",
    "#     5. NOX       nitric oxides concentration (parts per 10 million)\n",
    "#     6. RM        average number of rooms per dwelling\n",
    "#     7. AGE       proportion of owner-occupied units built prior to 1940\n",
    "#     8. DIS       weighted distances to five Boston employment centres\n",
    "#     9. RAD       index of accessibility to radial highways\n",
    "#     10. TAX      full-value property-tax rate per $10,000\n",
    "#     11. PTRATIO  pupil-teacher ratio by town\n",
    "#     12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks \n",
    "#                  by town\n",
    "#     13. LSTAT    % lower status of the population\n",
    "#     14. MEDV     Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LIBRARIES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD DATA\n",
    "train = pd.read_csv('housing_train.txt', sep = \"\\s+\",header=None)\n",
    "#data.columns = [\"a\", \"b\", \"c\", \"etc.\"]\n",
    "\n",
    "#split into features and labels\n",
    "train_x = train.iloc[:,0:13]\n",
    "train_y = train.iloc[:,13]\n",
    "\n",
    "x0 = np.ones(len(train_x))\n",
    "#train_x['b'] = pd.Series(x0)\n",
    "train_x = pd.concat([pd.Series(x0), train_x ], axis=1)\n",
    "\n",
    "test = pd.read_csv('housing_test.txt', sep = \"\\s+\",header=None)\n",
    "\n",
    "#split into features and labels\n",
    "test_x = test.iloc[:,0:13]\n",
    "test_y = test.iloc[:,13]\n",
    "\n",
    "\n",
    "#x0 = np.ones(len(test_x))\n",
    "#test_x['b'] = pd.Series(x0)\n",
    "test_x = pd.concat([pd.Series(x0), test_x ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature - Target\n",
    "Y = np.array(train_y, dtype=np.float64)\n",
    "X = np.array(train_x, dtype=np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT DESCENT\n",
    "#batch\n",
    "alpha = .00000001 #Step size\n",
    "iterations = 900000 #No. of iterations\n",
    "\n",
    "#stocastic\n",
    "# alpha = .00000000001 #Step size\n",
    "# iterations = 12000 #No. of iterations\n",
    "\n",
    "m = len(Y) #No. of data points\n",
    "np.random.seed(123) #Set the seed\n",
    "\n",
    "#weights = np.random.rand(14) #Pick some random values to start with\n",
    "weights = np.zeros(14)\n",
    "\n",
    "#GRADIENT DESCENT\n",
    "def gradient_descent(x, y, weights, iterations, alpha):\n",
    "    past_costs = []\n",
    "    \n",
    "    past_thetas = [weights]\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        #STOCHASTIC\n",
    "#         for i in range(len(x)):\n",
    "#             prediction = x[i].dot(weights)\n",
    "#             error = prediction - y[i]\n",
    "#             cost = np.dot(error.T, error)\n",
    "#             #past_costs.append(cost)\n",
    "#             weights = (alpha * np.dot(x[i].T, error))\n",
    "#             #past_thetas.append(weights)\n",
    "#         past_thetas.append(weights)\n",
    "#         past_costs.append(cost)\n",
    "        \n",
    "        #BATCH\n",
    "        prediction = x.dot(weights)\n",
    "        error = prediction - y\n",
    "        cost = np.dot(error.T, error)\n",
    "        past_costs.append(cost)\n",
    "\n",
    "        weights = weights - (alpha * np.dot(x.T, error))\n",
    "        past_thetas.append(weights)\n",
    "\n",
    "        \n",
    "    return past_thetas, past_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "t,c = gradient_descent(X,Y,weights, iterations, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10791.637053391918"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.43147359e-07, -4.32906742e-09, -1.74579645e-08, -9.19935921e-09,\n",
       "        6.93525370e-07,  4.84677997e-08,  1.22472330e-06, -2.68654026e-08,\n",
       "       -1.79230047e-07,  4.41916093e-08, -1.84340401e-09, -2.91179699e-07,\n",
       "       -2.36301542e-09,  1.02435882e-07])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[-1] - t[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 24.9229482842699\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation - RMSE\n",
    "def mse(Y, Y_pred):\n",
    "    mse = 0\n",
    "    for i in range(len(Y)):\n",
    "        mse += ((Y_pred[i]-Y[i]) ** 2) / len(Y)\n",
    "    return(mse)\n",
    "\n",
    "# Model Evaluation - R2 Score\n",
    "def r2_score(Y, Y_pred):\n",
    "    mean_y = np.mean(Y)\n",
    "    ss_tot = sum((Y - mean_y) ** 2)\n",
    "    ss_res = sum((Y - Y_pred) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "\n",
    "Y_pred = X.dot(t[-1])\n",
    "\n",
    "print(\"Train MSE: \" +str(mse(Y, Y_pred)))\n",
    "#print(r2_score(Y, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 23.388310069728696\n"
     ]
    }
   ],
   "source": [
    "Y_test = np.array(test_y)\n",
    "X_test = np.array(test_x)\n",
    "test_pred = X_test.dot(t[-1])\n",
    "print(\"Test MSE: \" + str(mse(Y_test, test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
